{
    "output_dir": "./mimiciv-trained/bart_HCM_loFF_Lprun/",
    "dataset_name": "./dataset/HealthCareMagic-200k_split.json",
    "overwrite_output_dir": true,
    "model_name_or_path": "facebook/bart-large",
    "config_name": "facebook/bart-large",
    "do_train": true,
    "do_eval": true,
    "do_predict": true,
    "fp16": true,
    "num_train_epochs": 10,
    "save_total_limit": 1,
    "save_strategy": "steps",
    "save_steps": 20000,
    "evaluation_strategy": "steps",
    "eval_steps": 20000,
    "load_best_model_at_end": true,
    "per_device_train_batch_size": 8,
    "per_device_eval_batch_size": 8,
    "gradient_accumulation_steps": 1,
    "predict_with_generate": true,
    "logging_steps": 10000,
    "warmup_steps": 1000,
    "preprocessing_num_workers": 2,
    "weight_decay": 0.01,
    "learning_rate": 1e-04,
    "generation_max_length": 50,
    "generation_num_beams": 1,
    "metric_for_best_model": "rouge1",
    "max_source_length": 512,
    "evaltest_generation_max_length": 128,
    "evaltest_generation_num_beams": 6,
    "lora_on_qv": false,
    "lora_on_ff": true,
    "lora_on_enc": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11
    ],
    "lora_on_dec": [
        0,
        1,
        2,
        3,
        4,
        5,
        6,
        7,
        8,
        9,
        10,
        11
    ],
    "lora_r": 16,
    "lora_alpha": 32,
    "lora_dropout": 0.1,
    "share_enc_layers": null,
    "share_dec_layers": null,
    "enc_layers_remain": [
        0,
        1,
        2,
        4,
        6,
        8,
        10,
        11
    ],
    "dec_layers_remain": [
        0,
        1,
        2,
        4,
        6,
        8,
        10,
        11
    ],
    "param_table": false,
    "evaluate_bleu": true,
    "dataset_columns": [
        "input",
        "output"
    ]
}